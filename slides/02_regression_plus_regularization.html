<!DOCTYPE html>
<html lang="en"><head>
<script src="02_regression_plus_regularization_files/libs/clipboard/clipboard.min.js"></script>
<script src="02_regression_plus_regularization_files/libs/quarto-html/tabby.min.js"></script>
<script src="02_regression_plus_regularization_files/libs/quarto-html/popper.min.js"></script>
<script src="02_regression_plus_regularization_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="02_regression_plus_regularization_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="02_regression_plus_regularization_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="02_regression_plus_regularization_files/libs/quarto-html/quarto-syntax-highlighting-9ea0a49c779b6fc496fdb60b6bf00fef.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">
<title>regression_plus_regularization</title>
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
<link rel="stylesheet" href="02_regression_plus_regularization_files/libs/revealjs/dist/reset.css">
<link rel="stylesheet" href="02_regression_plus_regularization_files/libs/revealjs/dist/reveal.css">
<style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
      }
    pre.numberSource { margin-left: 3em;  padding-left: 4px; }
    div.sourceCode
      { color: #657b83; background-color: #fdf6e3; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #657b83; } /* Normal */
    code span.al { color: #d33682; font-weight: bold; } /* Alert */
    code span.an { color: #268bd2; } /* Annotation */
    code span.at { color: #268bd2; } /* Attribute */
    code span.bn { color: #2aa198; } /* BaseN */
    code span.bu { color: #cb4b16; } /* BuiltIn */
    code span.cf { color: #859900; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #2aa198; } /* Char */
    code span.cn { color: #2aa198; font-weight: bold; } /* Constant */
    code span.co { color: #93a1a1; font-style: italic; } /* Comment */
    code span.cv { color: #2aa198; } /* CommentVar */
    code span.do { color: #dc322f; } /* Documentation */
    code span.dt { color: #b58900; font-weight: bold; } /* DataType */
    code span.dv { color: #2aa198; } /* DecVal */
    code span.er { color: #dc322f; text-decoration: underline; } /* Error */
    code span.ex { color: #268bd2; font-weight: bold; } /* Extension */
    code span.fl { color: #2aa198; } /* Float */
    code span.fu { color: #268bd2; } /* Function */
    code span.im { color: #2aa198; } /* Import */
    code span.in { color: #b58900; } /* Information */
    code span.kw { color: #859900; font-weight: bold; } /* Keyword */
    code span.op { color: #859900; } /* Operator */
    code span.ot { color: #859900; } /* Other */
    code span.pp { color: #cb4b16; } /* Preprocessor */
    code span.re { color: #268bd2; background-color: #eee8d5; } /* RegionMarker */
    code span.sc { color: #dc322f; } /* SpecialChar */
    code span.ss { color: #dc322f; } /* SpecialString */
    code span.st { color: #2aa198; } /* String */
    code span.va { color: #268bd2; } /* Variable */
    code span.vs { color: #2aa198; } /* VerbatimString */
    code span.wa { color: #cb4b16; } /* Warning */
  </style>
<link rel="stylesheet" href="02_regression_plus_regularization_files/libs/revealjs/dist/theme/quarto-61b8fe8fdb637f5238075e4cdce2e752.css">
<link href="02_regression_plus_regularization_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
<link href="02_regression_plus_regularization_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
<link href="02_regression_plus_regularization_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
<link href="02_regression_plus_regularization_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
<style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">


<section id="regularization-in-the-linear-model" class="title-slide slide level1 center" data-background-color="#447099"><h1>2. Regularization in the linear model</h1>
<h2>
Big data in Economics
</h2>
<h3>
Juan D. Montoro-Pons | 2024/25
</h3>
<aside class="notes"><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section><section id="basic-concepts" class="title-slide slide level1 center" data-background-color="#447099"><h1>Basic concepts</h1>

</section><section id="linear-regression-in-high-dimensions" class="slide level2" style="color:#447099"><h2>Linear regression in high dimensions</h2>
<p>&nbsp;</p>
<p>We know OLS produces unbiased estimates but variances can be large when</p>
<ul>
<li>Predictors are multicollinear or</li>
<li>Number of predictors is large</li>
</ul>
<p>In short when the number of predictors is large the linear regression model fails due to variability of the estimates. Furthermore there is no unique least squares solution when <span class="math inline">\(k&gt;n\)</span></p>
<blockquote>
<p>Goal: use the linear regression model for predictive purposes in a high-dimensions setting</p>
</blockquote>
</section><section id="prediction-and-errors" class="slide level2" style="color:#447099"><h2>Prediction and errors</h2>
<p>&nbsp;</p>
<p>Assume a relationship between an outcome <span class="math inline">\(y\)</span> and a set of <span class="math inline">\(k\)</span> predictors <span class="math inline">\(X=(X_1,X_2,\ldots X_k)\)</span> such that <span class="math display">\[y=f(X)+\epsilon\]</span></p>
<p>Then <span class="math inline">\(f\)</span> is the conditional mean of the response, i.e.&nbsp;<span class="math display">\[E(y|X)=f(X)\]</span></p>
<div title="Predictive inference">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Predictive inference</strong></p>
</div>
<div class="callout-content">
<ul>
<li><p>Goal: to estimate <span class="math inline">\(f\)</span> for predictive purposes, such that <span class="math inline">\(\hat{y}=\hat{f}(X)\)</span>.</p></li>
<li>
<p>The accuracy of predictions depends on</p>
<ul>
<li>Reducible error (<span class="math inline">\(\hat{f}\)</span> is not perfect estimate for <span class="math inline">\(f\)</span>)</li>
<li>Irreducible error (unexpected variability)</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div>
<aside class="notes"><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="estimating-f" class="slide level2 scrollable" style="color:#447099"><h2>Estimating <span class="math inline">\(f\)</span>
</h2>
<p>&nbsp;</p>
<ol type="1">
<li>
<p>Parametric methods:</p>
<ul>
<li>make assumptions about functional form <span class="math inline">\(f\)</span>
</li>
<li>use a procedure to fit/train the model to the training data</li>
</ul>
</li>
<li>
<p>Non-parametric methods:</p>
<ul>
<li>no assumption about <span class="math inline">\(f\)</span>, but provide an estimate that gets as close as possible to the training data points</li>
<li>they are more flexible in that can produce a wide range of shapes to estimate <span class="math inline">\(f\)</span> BUT require a large number of observations (more than in parametric methods)</li>
</ul>
</li>
</ol>
<p>&nbsp;</p>
<blockquote>
<p><a href="https://juandmontoro.github.io/bigDataEco/notebooks/parametric_vs_nonparam.ipynb">Click to download example</a></p>
</blockquote>
<aside class="notes"><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="assessing-model-accuracy" class="slide level2" style="color:#447099"><h2>Assessing model accuracy</h2>
<p>&nbsp;</p>
<p>In a regression setting the most commonly used measure of predictive quality is <span class="math display">\[MSE=\frac{1}{n}\sum_i(y_i-\hat{f}(x_i))^2\]</span></p>
<p>But what MSE?</p>
<ul>
<li>training MSE (expected to be reasonably good, or at least better than..)</li>
<li>test set MSE (on data not used for training)</li>
</ul>
<blockquote>
<p>Overfitting: small MSE training set but large MSE test set due to excess flexibility (less flexibility would have yielded smaller test MSE)</p>
</blockquote>
<aside class="notes"><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="the-mse-decomposition" class="slide level2" style="color:#447099"><h2>The MSE decomposition</h2>
<p>It can be shown that</p>
<p><span class="math display">\[MSE=E(y-\hat{f}(x))^2= \mathrm{Var}(\hat{f}(x))+\left(\mathrm{Bias}(\hat{f}(x))\right)^2+\mathrm{Var}(\epsilon)\]</span></p>
<ul>
<li><p>Variance of <span class="math inline">\(\hat{f}\)</span>: variability in <span class="math inline">\(\hat{f}\)</span>, i.e.&nbsp;how much predictions would change if trained on a different dataset. A high variance model is extremely sensitive to the data (related to overfitting). Usually flexibility and variance of methods are positively related</p></li>
<li><p>Bias of <span class="math inline">\(\hat{f}\)</span>: these are systematic error in a model’s predictions. Emerge due to the fact that we approximate the relation between <span class="math inline">\(y\)</span> and <span class="math inline">\(X\)</span> through a specific functional class (i.e.&nbsp;simplifying assumptions) which might be more simpler than the real-world mechanism (and result in the model underfitting the data). Generally, more flexible methods result in less bias.</p></li>
</ul>
<p>The minimization of the MSE requires a method that produces low variance and low bias (which tipically are inversely related to model complexity). In setting up a model one can introduce bias in a way that decreases variance enough to lower the overall mean squared error</p>
<aside class="notes"><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="model-complexity-and-bias-variance-tradeoff" class="slide level2" style="color:#447099"><h2>Model complexity and bias-variance tradeoff</h2>

<img data-src="pics/biasvariance.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes"><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="bias-variance-tradeoff-an-example" class="slide level2" style="color:#447099"><h2>Bias-Variance tradeoff: an example</h2>
<div class="panel-tabset">
<ul id="tabset-1" class="panel-tabset-tabby">
<li><a data-tabby-default="" href="#tabset-1-1">Test set predictions</a></li>
<li><a href="#tabset-1-2">Test set error</a></li>
</ul>
<div class="tab-content">
<div id="tabset-1-1">
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href=""></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href=""></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href=""></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> PolynomialFeatures</span>
<span id="cb1-4"><a href=""></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb1-5"><a href=""></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsRegressor</span>
<span id="cb1-6"><a href=""></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-7"><a href=""></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeRegressor</span>
<span id="cb1-8"><a href=""></a></span>
<span id="cb1-9"><a href=""></a><span class="co"># Generate synthetic data</span></span>
<span id="cb1-10"><a href=""></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb1-11"><a href=""></a>X <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">50</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)  <span class="co"># Feature is reshaped to create a 2D array with one column!</span></span>
<span id="cb1-12"><a href=""></a>y <span class="op">=</span> np.sin(X[:,<span class="dv">0</span>]) <span class="op">+</span> np.random.normal(<span class="dv">0</span>, <span class="fl">0.8</span>, X.shape[<span class="dv">0</span>])  <span class="co"># True function + noise. Note that X is a 2D array so we must pick one columns </span></span>
<span id="cb1-13"><a href=""></a><span class="co"># y = np.sin(X).ravel() + np.random.normal(0, 0.8, X.shape[0])  # Alternatively one can flatten the 2D array with ravel  </span></span>
<span id="cb1-14"><a href=""></a></span>
<span id="cb1-15"><a href=""></a><span class="co"># Train-test split</span></span>
<span id="cb1-16"><a href=""></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb1-17"><a href=""></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb1-18"><a href=""></a>degrees <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">3</span>,<span class="dv">15</span>]  <span class="co"># Polynomial degrees</span></span>
<span id="cb1-19"><a href=""></a></span>
<span id="cb1-20"><a href=""></a><span class="cf">for</span> i, d <span class="kw">in</span> <span class="bu">enumerate</span>(degrees, <span class="dv">1</span>):</span>
<span id="cb1-21"><a href=""></a>    poly <span class="op">=</span> PolynomialFeatures(degree<span class="op">=</span>d)</span>
<span id="cb1-22"><a href=""></a>    X_poly <span class="op">=</span> poly.fit_transform(X_train)</span>
<span id="cb1-23"><a href=""></a>    </span>
<span id="cb1-24"><a href=""></a>    model <span class="op">=</span> LinearRegression()</span>
<span id="cb1-25"><a href=""></a>    model.fit(X_poly, y_train)</span>
<span id="cb1-26"><a href=""></a>    </span>
<span id="cb1-27"><a href=""></a>    X_test_poly <span class="op">=</span> poly.transform(X_test)</span>
<span id="cb1-28"><a href=""></a>    y_pred <span class="op">=</span> model.predict(X_test_poly)</span>
<span id="cb1-29"><a href=""></a>    </span>
<span id="cb1-30"><a href=""></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">3</span>, i)</span>
<span id="cb1-31"><a href=""></a>    plt.scatter(X_train, y_train, color<span class="op">=</span><span class="st">'gray'</span>, label<span class="op">=</span><span class="st">'Train Data'</span>)</span>
<span id="cb1-32"><a href=""></a>    plt.scatter(X_test, y_test, color<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Test Data'</span>)</span>
<span id="cb1-33"><a href=""></a>    plt.plot(np.sort(X_test.ravel()), y_pred[np.argsort(X_test.ravel())], label<span class="op">=</span><span class="ss">f'Degree </span><span class="sc">{</span>d<span class="sc">}</span><span class="ss">'</span>, lw<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb1-34"><a href=""></a>    plt.plot(X, np.sin(X), label<span class="op">=</span><span class="st">'True Function'</span>, linestyle<span class="op">=</span><span class="st">'dashed'</span>, color<span class="op">=</span><span class="st">'black'</span>)</span>
<span id="cb1-35"><a href=""></a>    plt.title(<span class="ss">f'Polynomial Regression (Degree </span><span class="sc">{</span>d<span class="sc">}</span><span class="ss">)'</span>)</span>
<span id="cb1-36"><a href=""></a>    plt.legend()</span>
<span id="cb1-37"><a href=""></a></span>
<span id="cb1-38"><a href=""></a>plt.tight_layout()</span>
<span id="cb1-39"><a href=""></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div>
<figure><p><img data-src="02_regression_plus_regularization_files/figure-revealjs/unnamed-chunk-2-1.png" width="1152"></p>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-1-2">
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href=""></a><span class="im">from</span> mlxtend.evaluate <span class="im">import</span> bias_variance_decomp</span>
<span id="cb2-2"><a href=""></a></span>
<span id="cb2-3"><a href=""></a><span class="co"># Function to fit polynomial models</span></span>
<span id="cb2-4"><a href=""></a><span class="kw">def</span> fit_polynomial(degree):</span>
<span id="cb2-5"><a href=""></a>    poly_features <span class="op">=</span> PolynomialFeatures(degree<span class="op">=</span>degree) <span class="co"># creates polinomial and interaction terms up to degree selected</span></span>
<span id="cb2-6"><a href=""></a>    X_train_poly <span class="op">=</span> poly_features.fit_transform(X_train)</span>
<span id="cb2-7"><a href=""></a>    X_test_poly <span class="op">=</span> poly_features.transform(X_test)</span>
<span id="cb2-8"><a href=""></a>    model <span class="op">=</span> LinearRegression()</span>
<span id="cb2-9"><a href=""></a>    model.fit(X_train_poly, y_train)</span>
<span id="cb2-10"><a href=""></a>    y_pred <span class="op">=</span> model.predict(X_test_poly)</span>
<span id="cb2-11"><a href=""></a>    <span class="cf">return</span> y_pred</span>
<span id="cb2-12"><a href=""></a></span>
<span id="cb2-13"><a href=""></a><span class="co"># Degrees of polynomials to evaluate</span></span>
<span id="cb2-14"><a href=""></a>degrees <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">7</span>, <span class="dv">8</span>]  <span class="co"># Extended range</span></span>
<span id="cb2-15"><a href=""></a></span>
<span id="cb2-16"><a href=""></a><span class="co"># Calculate bias and variance for each degree</span></span>
<span id="cb2-17"><a href=""></a>mse_scores <span class="op">=</span> []</span>
<span id="cb2-18"><a href=""></a>bias_scores <span class="op">=</span> []</span>
<span id="cb2-19"><a href=""></a>variance_scores <span class="op">=</span> []</span>
<span id="cb2-20"><a href=""></a>predictions_dict <span class="op">=</span> {}</span>
<span id="cb2-21"><a href=""></a></span>
<span id="cb2-22"><a href=""></a><span class="cf">for</span> degree <span class="kw">in</span> degrees:</span>
<span id="cb2-23"><a href=""></a>    poly_features <span class="op">=</span> PolynomialFeatures(degree<span class="op">=</span>degree)</span>
<span id="cb2-24"><a href=""></a>    X_train_poly <span class="op">=</span> poly_features.fit_transform(X_train)</span>
<span id="cb2-25"><a href=""></a>    X_test_poly <span class="op">=</span> poly_features.transform(X_test)</span>
<span id="cb2-26"><a href=""></a></span>
<span id="cb2-27"><a href=""></a>    mse, bias, var <span class="op">=</span> bias_variance_decomp(</span>
<span id="cb2-28"><a href=""></a>        LinearRegression(), </span>
<span id="cb2-29"><a href=""></a>        X_train_poly, </span>
<span id="cb2-30"><a href=""></a>        y_train, </span>
<span id="cb2-31"><a href=""></a>        X_test_poly, </span>
<span id="cb2-32"><a href=""></a>        y_test, </span>
<span id="cb2-33"><a href=""></a>        loss<span class="op">=</span><span class="st">'mse'</span>, </span>
<span id="cb2-34"><a href=""></a>        num_rounds<span class="op">=</span><span class="dv">500</span>,  <span class="co"># bootstrapped </span></span>
<span id="cb2-35"><a href=""></a>        random_seed<span class="op">=</span><span class="dv">1</span></span>
<span id="cb2-36"><a href=""></a>    )</span>
<span id="cb2-37"><a href=""></a>    </span>
<span id="cb2-38"><a href=""></a>    mse_scores.append(mse)</span>
<span id="cb2-39"><a href=""></a>    bias_scores.append(bias)</span>
<span id="cb2-40"><a href=""></a>    variance_scores.append(var)</span>
<span id="cb2-41"><a href=""></a>    predictions_dict[<span class="ss">f'Degree_</span><span class="sc">{</span>degree<span class="sc">}</span><span class="ss">'</span>] <span class="op">=</span> fit_polynomial(degree)</span>
<span id="cb2-42"><a href=""></a></span>
<span id="cb2-43"><a href=""></a><span class="co"># Plot the results</span></span>
<span id="cb2-44"><a href=""></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb2-45"><a href=""></a>plt.plot(degrees, mse_scores, label<span class="op">=</span><span class="st">'MSE'</span>)</span>
<span id="cb2-46"><a href=""></a>plt.plot(degrees, bias_scores, label<span class="op">=</span><span class="st">'Bias^2'</span>)</span>
<span id="cb2-47"><a href=""></a>plt.plot(degrees, variance_scores, label<span class="op">=</span><span class="st">'Variance'</span>)</span>
<span id="cb2-48"><a href=""></a></span>
<span id="cb2-49"><a href=""></a><span class="co"># Find the plynomial degree that minimizes the MSE</span></span>
<span id="cb2-50"><a href=""></a>min_mse_index <span class="op">=</span> mse_scores.index(<span class="bu">min</span>(mse_scores))</span>
<span id="cb2-51"><a href=""></a>min_mse_degree <span class="op">=</span> degrees[min_mse_index]</span>
<span id="cb2-52"><a href=""></a></span>
<span id="cb2-53"><a href=""></a><span class="co"># Add a vertical dashed line at the degree that minimizes MSE</span></span>
<span id="cb2-54"><a href=""></a>plt.axvline(x<span class="op">=</span>min_mse_degree, color<span class="op">=</span><span class="st">'r'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="ss">f'Min MSE Degree = </span><span class="sc">{</span>min_mse_degree<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb2-55"><a href=""></a></span>
<span id="cb2-56"><a href=""></a><span class="co"># Add plot labels etc</span></span>
<span id="cb2-57"><a href=""></a>plt.xlabel(<span class="st">'Polynomial Degree'</span>)</span>
<span id="cb2-58"><a href=""></a>plt.ylabel(<span class="st">'Score'</span>)</span>
<span id="cb2-59"><a href=""></a>plt.legend()</span>
<span id="cb2-60"><a href=""></a>plt.title(<span class="st">'Bias-Variance Trade-off'</span>)</span>
<span id="cb2-61"><a href=""></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div>
<figure><p><img data-src="02_regression_plus_regularization_files/figure-revealjs/unnamed-chunk-3-3.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</section><section id="choosing-the-optimal-f-within-a-functional-class" class="slide level2 scrollable" style="color:#447099"><h2>Choosing the optimal <span class="math inline">\(f\)</span> (within a functional class)</h2>
<p>&nbsp;</p>
<p>In order to select the best model with respect to test error, we need to estimate the test error associated to each model. Two common approaches:</p>
<ol type="1">
<li><p>Indirectly estimate test error by making an adjustment to the training error to account for potential overfitting: AIC, BIC or adjusted R<span class="math inline">\(^2\)</span>.</p></li>
<li><p>Directly estimate the test error using resamplig methods.</p></li>
</ol>
<aside class="notes"><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section></section><section><section id="resampling-methods" class="title-slide slide level1 center" data-background-color="#447099"><h1>Resampling methods</h1>

</section><section id="motivation" class="slide level2" style="color:#447099"><h2>Motivation</h2>
<p>&nbsp;</p>
<ul>
<li><p>A sample <span class="math inline">\((x_1,y_1), (x_2,y_2) \ldots (x_n,y_n)\)</span> is used to fit a model for predictive purposes</p></li>
<li><p>A linear model is to be used but we can accomodate for non-linearities by using polynomials of the predictor</p></li>
<li><p>The goal is to choose the model that minimizes test error rate (MSE on unseen or new data)</p></li>
</ul>
<blockquote>
<p>Resampling methods involve repeatedly drawing samples from a training set and refitting a model of interest on each sample in order to obtain additional information about the fitted model</p>
</blockquote>
</section><section id="validation-set-approach" class="slide level2 scrollable" style="color:#447099"><h2>Validation set approach</h2>
<div title="Procedure">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Procedure</strong></p>
</div>
<div class="callout-content">
<ol type="1">
<li><p>A set of <span class="math inline">\(n\)</span> observations are randomly split into a training set and a validation set.</p></li>
<li><p>The model is fit on the training set, and its performance is evaluated on the validation set.</p></li>
</ol>
</div>
</div>
</div>
</div>

<img data-src="pics/validation_set.webp" class="r-stretch"><aside class="notes"><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="leave-one-out-cross-validation" class="slide level2 scrollable" style="color:#447099"><h2>Leave-one-out cross-validation</h2>
<div title="Procedure">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Procedure</strong></p>
</div>
<div class="callout-content">
<ol type="1">
<li>
<p>Use a single observation <span class="math inline">\((x_1,y_1)\)</span> as validation set and fit the model using the <span class="math inline">\(n-1\)</span> training observations.</p>
<ul>
<li>Compute <span class="math inline">\(\textrm{MSE}_1=\sum(y_1-\hat{y}_1)\)</span>
</li>
</ul>
</li>
<li><p>Iterate the procedure using observation <span class="math inline">\(i=2\ldots n\)</span> as validation set.</p></li>
</ol>
<p>The LOOCV estimate for the test MSE is the average of the computed test error estimates:</p>
<p><span class="math display">\[CV(n)=\frac{1}{n}\sum_i \textrm{MSE}_i\]</span></p>
</div>
</div>
</div>
</div>

<img data-src="pics/loocv.webp" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes"><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="k-fold-cross-validation" class="slide level2" style="color:#447099"><h2>
<span class="math inline">\(k\)</span>-fold cross-validation</h2>
<div title="Procedure">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Procedure</strong></p>
</div>
<div class="callout-content">
<p>In <span class="math inline">\(k\)</span>-fold cross-validation, a dataset of <span class="math inline">\(n\)</span> observations is randomly partitioned into <span class="math inline">\(k\)</span> non-overlapping subsets. In each iteration:</p>
<ul>
<li>One subset is designated as the validation set.</li>
<li>The remaining k-1 subsets are combined to form the training set.</li>
<li>A model is trained on the training set and evaluated (MSE is computed) on the validation set.</li>
</ul>
<p>This process is repeated <span class="math inline">\(k\)</span> times, with each subset serving as the validation set once. The CV estimate for the error test MSE is the average of the computed test error estimates:</p>
<p><span class="math display">\[CV(k)=\frac{1}{k}\sum_i \textrm{MSE}_i\]</span></p>
</div>
</div>
</div>
</div>

<img data-src="pics/crossvalidation.webp" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes"><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="trainingtest-partitioning-cross-validation" class="slide level2" style="color:#447099"><h2>Training/test partitioning + cross validation</h2>

<img data-src="pics/grid_search_cross_validation.png" width="100" class="r-stretch quarto-figure-center"><p class="caption">Source: sklearn documentation</p></section><section id="resampling-in-practice" class="slide level2" style="color:#447099"><h2>Resampling in practice</h2>
<p>&nbsp;</p>
<p>Resampling provides an empirical method to choose between and within predictor classes. How?</p>
<p>We aim at at building the best prediction for <span class="math inline">\(y\)</span>. Let us have alternative functional classes <span class="math inline">\(f_1\)</span>, <span class="math inline">\(f_2,f_3 \ldots\)</span>:</p>
<ul>
<li><p>Split the data into training and testing sets</p></li>
<li><p>Train different regularized models of one class <span class="math inline">\(f_i\)</span> using resampling. Choose the best performing model on that class (empirically select tuning parameters)</p></li>
<li><p>Among the different model classes select the one that performs best on the test set</p></li>
</ul></section></section><section><section id="penalized-linear-regression" class="title-slide slide level1 center" data-background-color="#447099"><h1>Penalized linear regression</h1>

</section><section id="shrinkage-methods" class="slide level2" style="color:#447099"><h2>Shrinkage methods</h2>
<p>&nbsp;</p>
<p>Techniques that constrain or regularize coefficient estimates, shrinking them towards zero.</p>
<ul>
<li>Purpose: Reduces variance of coefficient estimates, potentially improving model fit.</li>
<li>Two main techniques:
<ul>
<li>Ridge Regression: adds a penalty equal to the sum of the squared coefficients.</li>
<li>Lasso (Least Absolute Shrinkage and Selection Operator): adds a penalty equal to the sum of the absolute values of the coefficients.</li>
</ul>
</li>
</ul></section><section id="ridge-regression" class="slide level2" style="color:#447099"><h2>Ridge regression</h2>
<p>&nbsp; Loss function in OLS</p>
<p><span class="math display">\[RSS = \sum_i \left( y_i-x_i\beta \right)^2\]</span></p>
<p>Ridge regression (L2 regression or L2 regularization) modifies the loss function in least squares so the values minimize</p>
<p><span class="math display">\[RSS+\lambda \sum_j \beta_j^2\]</span> with <span class="math inline">\(\lambda\geq0\)</span>, also known as the tuning parameter, to be determined independently.</p>
<blockquote>
<p>Ridge regression introduces a penalty in the loss function that grows with the magnitude of the squared coefficients. As we increase the value of <span class="math inline">\(\lambda\)</span> we effectively shrink estimates towards zero.</p>
</blockquote>
</section><section id="ridge-regression-1" class="slide level2" style="color:#447099"><h2>Ridge regression</h2>
<p>&nbsp;</p>
<ul>
<li><p>Different values of the penalty terms <span class="math inline">\(\lambda\)</span> regression generate a different set of coefficient estimates</p></li>
<li><p>Penalty is applied to all coefficients but the intercept (focus is on the coefficents of the predictors)</p></li>
<li><p>Method is not scale-invariant (need to standardize predictors)</p></li>
<li><p>Ridge coefficients are biased (towards zero) but have smaller variance than OLS</p></li>
<li><p>Suited for multicollinearity (originally developed as a possible solution to the imprecision of least square estimators)</p></li>
<li><p>Ridge regression can be expressed as a minimization problem subject to a “budget” constraint:</p></li>
</ul>
<p><span class="math display">\[\textrm{minimize } \sum_i \left( y_i-x_i\beta \right)^2 s.t. \sum_j\beta_j^2 \leq s\]</span></p>
<blockquote>
<p>Choose optimal penalty <span class="math inline">\(lambda\)</span> through resampling (cross-validation)</p>
</blockquote>
</section><section id="ridge-regression-visual-interpretation" class="slide level2" style="color:#447099"><h2>Ridge regression: visual interpretation</h2>
<p>&nbsp;</p>
<p>If one considers the two predictors case, then ridge regression chooses the coefficients that minimize RSS and lie in the circle <span class="math inline">\(\beta_1^2+\beta_2^2\leq s\)</span>. Then:</p>

<img data-src="pics/RIDGE_PLOT.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes"><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="lasso-regression" class="slide level2" style="color:#447099"><h2>LASSO Regression</h2>
<p>LASSO stands for least absolute shrinkage and selection operator. It is also called L1 regression or L1 regularization and modifies the loss function in least squares so the values minimize</p>
<p><span class="math display">\[RSS+\lambda \sum_j |\beta_j|\]</span> with <span class="math inline">\(\lambda\geq0\)</span>, also known as the tuning parameter, to be determined independently.</p>
<blockquote>
<p>LASSO regression introduces a penalty in the loss function that grows with the magnitude of the coefficients. As we increase the value of <span class="math inline">\(\lambda\)</span> we effectively force more coefficients to be zero</p>
</blockquote>
</section><section id="lasso-regression-1" class="slide level2" style="color:#447099"><h2>LASSO regression</h2>
<p>&nbsp;</p>
<ul>
<li><p>While LASSO also shrinks the coefficients in the linear regression, for large enough values of the penalty terms <span class="math inline">\(\lambda\)</span> it forces some coefficients to be exactly zero. Hence LASSO performs <em>variable selection</em></p></li>
<li><p>Not scale-invariant (need to standardize predictors)</p></li>
<li><p>Coefficients are also biased (towards zero) and smaller variance than OLS</p></li>
<li><p>As with ridge regression, LASSO can be reformulated as</p></li>
</ul>
<p><span class="math display">\[\textrm{minimize } \sum_i \left( y_i-x_i\beta \right)^2 s.t. \sum_j |\beta_j| \leq s\]</span></p>
<blockquote>
<p>Choose optimal penalty <span class="math inline">\(\lambda\)</span> through resampling (cross-validation)</p>
</blockquote>
</section><section id="lasso-visual-interpretation" class="slide level2" style="color:#447099"><h2>LASSO: visual interpretation</h2>
<p>&nbsp;</p>
<p>If one considers the two predictors case, then LASSO regression chooses the coefficients that minimize RSS and lie in the area <span class="math inline">\(|\beta_1|+|\beta_2|\leq s\)</span> (diamond-shaped).</p>
<p>Then:</p>

<img data-src="pics/LASSO_PLOT.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes"><style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside></section><section id="elastic-net" class="slide level2" style="color:#447099"><h2>Elastic net</h2>
<p>&nbsp;</p>
<ul>
<li>The Elastic Net method regularizes least squares by adding a penalty to the loss function given by a linear combination of the LASSO and ridge penalties</li>
</ul>
<p><span class="math display">\[ \sum_i \left( y_i-x_i\beta \right)^2 + \lambda \left( \alpha \sum_j|\beta_j| + \frac{1-\alpha}{2} \sum_j\beta_j^2   \right)\]</span></p>
<ul>
<li><p>In this case two hyperparameters (<span class="math inline">\(\lambda\)</span> and <span class="math inline">\(\alpha\)</span>) need to be chosen</p></li>
<li><p><span class="math inline">\(\lambda\)</span> controls the penalty and <span class="math inline">\(\alpha\)</span> the LASSO-ridge mix</p></li>
<li><p>Elastic net performs variable selection unless we set <span class="math inline">\(\alpha=0\)</span></p></li>
</ul>
<blockquote>
<p>Choose optimal tuning parameters through resampling (cross-validation)</p>
</blockquote>
</section><section id="other-approaches-for-high-dimensional-regression" class="slide level2" style="color:#447099"><h2>Other approaches for high-dimensional regression</h2>
<p>&nbsp;</p>
<ul>
<li>Subset selection (e.g.&nbsp;stepwise selection)</li>
<li>Dimension reduction methods
<ul>
<li>Principal components regression</li>
<li>Partial least squares</li>
</ul>
</li>
</ul></section><section id="regression-in-high-dimensions" class="slide level2 scrollable" style="color:#447099"><h2>Regression in high dimensions</h2>
<p>It turns out that methods for fitting less flexible least squares models, ridge and lasso regression (but also principal components regression and partial least squares) are particularly useful for performing regression in the high-dimensional setting. Essentially, these approaches avoid overfitting by using a less flexible fitting approach than least squares.</p>
<p>Three important points from high dimensional regression problems:</p>
<ol type="1">
<li><p>Regularization or shrinkage plays a key role in high-dimensional problems</p></li>
<li><p>Appropriate tuning parameter selection is crucial for good predictive performance,</p></li>
<li><p>The test error tends to increase as the dimensionality of the problem (i.e.&nbsp;the number of features or predictors) increases, unless the additional features are truly associated with the response.</p></li>
</ol>

</section></section>
</div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="02_regression_plus_regularization_files/libs/revealjs/dist/reveal.js"></script><!-- reveal.js plugins --><script src="02_regression_plus_regularization_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script><script src="02_regression_plus_regularization_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script><script src="02_regression_plus_regularization_files/libs/revealjs/plugin/reveal-menu/menu.js"></script><script src="02_regression_plus_regularization_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script><script src="02_regression_plus_regularization_files/libs/revealjs/plugin/quarto-support/support.js"></script><script src="02_regression_plus_regularization_files/libs/revealjs/plugin/notes/notes.js"></script><script src="02_regression_plus_regularization_files/libs/revealjs/plugin/search/search.js"></script><script src="02_regression_plus_regularization_files/libs/revealjs/plugin/zoom/zoom.js"></script><script src="02_regression_plus_regularization_files/libs/revealjs/plugin/math/math.js"></script><script>window.define = window.backupDefine; window.backupDefine = undefined;</script><script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1920,

        height: 1080,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script><script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script><script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
          let selectedAnnoteEl;
          const selectorForAnnotation = ( cell, annotation) => {
            let cellAttr = 'data-code-cell="' + cell + '"';
            let lineAttr = 'data-code-annotation="' +  annotation + '"';
            const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
            return selector;
          }
          const selectCodeLines = (annoteEl) => {
            const doc = window.document;
            const targetCell = annoteEl.getAttribute("data-target-cell");
            const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
            const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
            const lines = annoteSpan.getAttribute("data-code-lines").split(",");
            const lineIds = lines.map((line) => {
              return targetCell + "-" + line;
            })
            let top = null;
            let height = null;
            let parent = null;
            if (lineIds.length > 0) {
                //compute the position of the single el (top and bottom and make a div)
                const el = window.document.getElementById(lineIds[0]);
                top = el.offsetTop;
                height = el.offsetHeight;
                parent = el.parentElement.parentElement;
              if (lineIds.length > 1) {
                const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
                const bottom = lastEl.offsetTop + lastEl.offsetHeight;
                height = bottom - top;
              }
              if (top !== null && height !== null && parent !== null) {
                // cook up a div (if necessary) and position it 
                let div = window.document.getElementById("code-annotation-line-highlight");
                if (div === null) {
                  div = window.document.createElement("div");
                  div.setAttribute("id", "code-annotation-line-highlight");
                  div.style.position = 'absolute';
                  parent.appendChild(div);
                }
                div.style.top = top - 2 + "px";
                div.style.height = height + 4 + "px";
                div.style.left = 0;
                let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
                if (gutterDiv === null) {
                  gutterDiv = window.document.createElement("div");
                  gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                  gutterDiv.style.position = 'absolute';
                  const codeCell = window.document.getElementById(targetCell);
                  const gutter = codeCell.querySelector('.code-annotation-gutter');
                  gutter.appendChild(gutterDiv);
                }
                gutterDiv.style.top = top - 2 + "px";
                gutterDiv.style.height = height + 4 + "px";
              }
              selectedAnnoteEl = annoteEl;
            }
          };
          const unselectCodeLines = () => {
            const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
            elementsIds.forEach((elId) => {
              const div = window.document.getElementById(elId);
              if (div) {
                div.remove();
              }
            });
            selectedAnnoteEl = undefined;
          };
            // Handle positioning of the toggle
        window.addEventListener(
          "resize",
          throttle(() => {
            elRect = undefined;
            if (selectedAnnoteEl) {
              selectCodeLines(selectedAnnoteEl);
            }
          }, 10)
        );
        function throttle(fn, ms) {
        let throttle = false;
        let timer;
          return (...args) => {
            if(!throttle) { // first call gets through
                fn.apply(this, args);
                throttle = true;
            } else { // all the others get throttled
                if(timer) clearTimeout(timer); // cancel #2
                timer = setTimeout(() => {
                  fn.apply(this, args);
                  timer = throttle = false;
                }, ms);
            }
          };
        }
          const annoteTargets = window.document.querySelectorAll('.code-annotation-anchor');
          for (let i=0; i<annoteTargets.length; i++) {
            const annoteTarget = annoteTargets[i];
            const targetCell = annoteTarget.getAttribute("data-target-cell");
            const targetAnnotation = annoteTarget.getAttribute("data-target-annotation");
            const contentFn = () => {
              const content = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
              if (content) {
                const tipContent = content.cloneNode(true);
                tipContent.classList.add("code-annotation-tip-content");
                return tipContent.outerHTML;
              }
            }
            const config = {
              allowHTML: true,
              content: contentFn,
              onShow: (instance) => {
                selectCodeLines(instance.reference);
                instance.reference.classList.add('code-annotation-active');
                window.tippy.hideAll();
              },
              onHide: (instance) => {
                unselectCodeLines();
                instance.reference.classList.remove('code-annotation-active');
              },
              maxWidth: 300,
              delay: [50, 0],
              duration: [200, 0],
              offset: [5, 10],
              arrow: true,
              appendTo: function(el) {
                return el.parentElement.parentElement.parentElement;
              },
              interactive: true,
              interactiveBorder: 10,
              theme: 'light-border',
              placement: 'right',
              popperOptions: {
                modifiers: [
                {
                  name: 'flip',
                  options: {
                    flipVariations: false, // true by default
                    allowedAutoPlacements: ['right'],
                    fallbackPlacements: ['right', 'top', 'top-start', 'top-end', 'bottom', 'bottom-start', 'bottom-end', 'left'],
                  },
                },
                {
                  name: 'preventOverflow',
                  options: {
                    mainAxis: false,
                    altAxis: false
                  }
                }
                ]        
              }      
            };
            window.tippy(annoteTarget, config); 
          }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>


</body></html>